{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document-at-a-time scoring\n",
    "\n",
    "  - Implement document-at-a-time scoring using vector space retrieval with TFIDF term weighting\n",
    "  - Use the TF-IDF weighting schemes from the previous task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term-document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "td_matrix = {\n",
    "    \"beijing\": [0, 1, 0, 0, 1],\n",
    "    \"dish\": [0, 1, 0, 0, 1],\n",
    "    \"duck\": [3, 2, 2, 0, 1],\n",
    "    \"rabbit\": [0, 0, 1, 1, 0],\n",
    "    \"recipe\": [0, 0, 1, 1, 1],\n",
    "    \"roast\": [0, 0, 0, 0, 0]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of documents is set manually for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_DOCS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the corresponding inverted index\n",
    "\n",
    "The postings hold (docID, freq) pairs. docID indices start from 0\n",
    "\n",
    "`doclen` stores the document length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'beijing': [(1, 1), (4, 1)],\n",
      " 'dish': [(1, 1), (4, 1)],\n",
      " 'duck': [(0, 3), (1, 2), (2, 2), (4, 1)],\n",
      " 'rabbit': [(2, 1), (3, 1)],\n",
      " 'recipe': [(2, 1), (3, 1), (4, 1)],\n",
      " 'roast': []}\n"
     ]
    }
   ],
   "source": [
    "inv_idx = {}\n",
    "doclen = {}\n",
    "for term, vec in td_matrix.items():\n",
    "    inv_idx[term] = []\n",
    "    for doc_id, freq in enumerate(vec):\n",
    "        if freq > 0:\n",
    "            inv_idx[term].append((doc_id, freq))\n",
    "            doclen[doc_id] = doclen.get(doc_id, 0) + freq\n",
    "\n",
    "pprint(inv_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This class provides access to the inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class InvIndex(object):\n",
    "    def __init__(self, idx_contents):\n",
    "        self.idx = idx_contents\n",
    "    \n",
    "    def postings(self, term):\n",
    "        return self.idx.get(term, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the InvIndex class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = InvIndex(inv_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IDF calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def idf(term):\n",
    "    return math.log(NUM_DOCS / len(idx.postings(term))) if len(idx.postings(term)) > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document-at-a-time scoring\n",
    "\n",
    "We utilize the fact that the posting lists are ordered by document ID. \n",
    "The posting lists of the query terms are iterated parallel to each other (we always read from the beginning of the list and delete the posting once the current document has been processed).\n",
    "Each document is scored according to\n",
    "\n",
    "$Score(q,d) = \\sum_{t \\in q} w_{t,q} \\times w_{t,d}$\n",
    "\n",
    "where $w_{t,d}=\\frac{tfidf_{t,d}}{\\sqrt{\\sum_{t} tfidf_{t,d}^2}}$ and $w_{t,q}=\\frac{tfidf_{t,q}}{\\sqrt{\\sum_{t} tfidf_{t,q}^2}}$\n",
    "\n",
    "(which is the same as before).\n",
    "\n",
    "Here, we cache the query tfidf scores ($tfidf_{t,q}$) and the query normalizer ($\\sqrt{\\sum_{t} tfidf_{t,q}^2}$), so that these are computed only once in the beginning, and not for each document. \n",
    "\n",
    "Further, the document normalizers are also pre-computed (since it's a const value for each doc); for simplicity, this latter computation is based on the term-document matrix, and not on the inverted index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dnorm = {}\n",
    "for term, vec in td_matrix.items():\n",
    "    for doc_id, freq in enumerate(vec):\n",
    "        if freq > 0:\n",
    "            tfidf = freq / doclen[doc_id] * idf(term)\n",
    "            dnorm[doc_id] = dnorm.get(doc_id, 0) + tfidf**2\n",
    "for doc_id, val in dnorm.items():\n",
    "    dnorm[doc_id] = math.sqrt(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def score_dt(query, index):\n",
    "    # change the sequence of query terms into a \"term: freq\" dictionary\n",
    "    qry = dict(Counter(query))\n",
    "\n",
    "    # prepcompute the query TFIDF scores and the query normalizer\n",
    "    tfidf_q = {}\n",
    "    qnorm = 0\n",
    "    for term, freq in qry.items():\n",
    "        tf = freq / len(query)\n",
    "        tfidf_q[term] = tf * idf(term)\n",
    "        qnorm += tfidf_q[term]**2\n",
    "    qnorm = math.sqrt(qnorm)\n",
    "    \n",
    "    # fetch the posting lists of each query term\n",
    "    plists = {}  # holds a copy of the posting list for query term i\n",
    "    for term in qry.keys():\n",
    "        plists[term] = list(index.postings(term))  # need to copy the list!\n",
    "        \n",
    "    scores = {}  # holds the final document scores\n",
    "\n",
    "    # iterate through each document\n",
    "    for doc_id in range(NUM_DOCS):            \n",
    "        # i) first, we collect the document term frequencies from the index\n",
    "        # (Essentially, we just \"recover\" the document's contents from the index.)\n",
    "        f_d = {}  # holds the term frequencies in the document\n",
    "        for term in qry.keys(): \n",
    "            # TODO: get the frequency of query term i from the posting list\n",
    "            f_d[term] = 0\n",
    "                    \n",
    "        # ii) then, we score the document\n",
    "        score = 0  # holds the document's retrieval score\n",
    "        for term in qry.keys(): \n",
    "            # incement the document's score according to the given query term\n",
    "            tfidf_d = 0  # TODO: compute the term's TFIDF score in the document\n",
    "            score += tfidf_q[term] * tfidf_d\n",
    "        # final document score, with the query and document normalizers        \n",
    "        scores[doc_id] = score / (qnorm * dnorm[doc_id])\n",
    "    return scores\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = [\"beijing\", \"duck\", \"recipe\"]\n",
    "scores = score_dt(query, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D1: 0.0\n",
      "D2: 0.0\n",
      "D3: 0.0\n",
      "D4: 0.0\n",
      "D5: 0.0\n"
     ]
    }
   ],
   "source": [
    "for doc_id, score in sorted(scores.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(\"D\" + str(doc_id + 1) + \":\", round(score, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
